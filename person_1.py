# -*- coding: utf-8 -*-
"""Person_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CraqqEri6AcPJrdc7xDH4_wmkYKEg5eI
"""

# Commented out IPython magic to ensure Python compatibility.
# %ls
# %cd drive/MyDrive/Colab Notebooks/Attendance_System/Person_1
# %ls

# # Rename Folder name and put serial number
# import os

# # Specify the folder path containing the files
# folder_path = 'Dataset/'


# nameList = ["Emily", "Benjamin", "Sophia", "Alexander", "Olivia", "William", "Ava", "James", "Mia", "Ethan"]

# # Get a list of all files in the folder
# files = os.listdir(folder_path)

# # Sort the files alphabetically
# files.sort()

# # Rename the files with sequential numbers
# for i, file_name in enumerate(files):
#     # Generate the new file name
#     new_file_name = nameList[i]

#     # Generate the current and new file paths
#     current_path = os.path.join(folder_path, file_name)
#     new_path = os.path.join(folder_path, new_file_name)

#     # Rename the file
#     os.rename(current_path, new_path)

# print("Files renamed successfully!")

from sklearn.model_selection import train_test_split
import os
import shutil
from tqdm import tqdm

# Define the path to your dataset directory containing 10 folders
dataset_dir = 'Dataset/Input'

# Define the path for the output directory
output_dir = 'Dataset/Output'

# Define the ratio for train, validation, and test sets
train_ratio = 0.7
val_ratio = 0.2
test_ratio = 0.1

# Create directories for train, validation, and test sets
train_dir = os.path.join(output_dir, 'train')
val_dir = os.path.join(output_dir, 'validation')
test_dir = os.path.join(output_dir, 'test')

os.makedirs(train_dir, exist_ok=True)
os.makedirs(val_dir, exist_ok=True)
os.makedirs(test_dir, exist_ok=True)

# Iterate over the folders in the dataset directory
for folder_name in os.listdir(dataset_dir):
    folder_path = os.path.join(dataset_dir, folder_name)

    # Split the data in each folder into train and temp sets
    folder_train_data, folder_temp_data = train_test_split(os.listdir(folder_path), test_size=(1 - train_ratio))

    # Split the temp data into validation and test sets
    folder_val_data, folder_test_data = train_test_split(folder_temp_data, test_size=test_ratio / (test_ratio + val_ratio))

    # Create subdirectories within train, validation, and test directories based on folder names
    train_subdir = os.path.join(train_dir, folder_name)
    val_subdir = os.path.join(val_dir, folder_name)
    test_subdir = os.path.join(test_dir, folder_name)

    os.makedirs(train_subdir, exist_ok=True)
    os.makedirs(val_subdir, exist_ok=True)
    os.makedirs(test_subdir, exist_ok=True)

    # Move images to respective directories
    for image_file in folder_train_data:
        src_path = os.path.join(folder_path, image_file)
        dest_path = os.path.join(train_subdir, image_file)
        shutil.copy(src_path, dest_path)

    for image_file in folder_val_data:
        src_path = os.path.join(folder_path, image_file)
        dest_path = os.path.join(val_subdir, image_file)
        shutil.copy(src_path, dest_path)

    for image_file in folder_test_data:
        src_path = os.path.join(folder_path, image_file)
        dest_path = os.path.join(test_subdir, image_file)
        shutil.copy(src_path, dest_path)

print("Data split and saved successfully!")

# Commented out IPython magic to ensure Python compatibility.
# %ls

import os
import random
import numpy as np
import shutil
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.metrics import confusion_matrix, precision_score, recall_score
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from tensorflow.keras.callbacks import ModelCheckpoint

import os
import random
import numpy as np
from sklearn.model_selection import train_test_split

# Set seed for reproducibility
np.random.seed(42)

# Define input directory
input_directory = "Dataset/Input/"

# Load the image paths
image_paths = []
for person_folder in os.listdir(input_directory):
    person_folder_path = os.path.join(input_directory, person_folder)
    if os.path.isdir(person_folder_path):
        person_images = [os.path.join(person_folder_path, image) for image in os.listdir(person_folder_path)]
        image_paths.extend(person_images)

# Split the image paths into train, validation, and test sets
train_paths, val_paths = train_test_split(image_paths, test_size=0.3, random_state=42)
val_paths, test_paths = train_test_split(val_paths, test_size=0.5, random_state=42)

# Print the number of images in each set
print("Number of training images:", len(train_paths))
print("Number of validation images:", len(val_paths))
print("Number of test images:", len(test_paths))

print("Number of training images:", train_paths)

# Define image dimensions and batch size
img_width, img_height = 150, 150
batch_size = 32

train_labels = []
val_labels = []
test_labels = []

for path in train_paths:
  t_label = path.split('/')[2];
  train_labels.append(t_label)

for path in val_paths:
  v_label = path.split('/')[2];
  val_labels.append(v_label)

for path in test_paths:
  te_label = path.split('/')[2];
  test_labels.append(te_label)

import pandas as pd

# Create a DataFrame with image paths and their corresponding labels
train_df = pd.DataFrame({'path': train_paths, 'label': train_labels})  # Replace train_labels with your actual labels
val_df = pd.DataFrame({'path': val_paths, 'label': val_labels})  # Replace val_labels with your actual labels
test_df = pd.DataFrame({'path': test_paths, 'label': test_labels})  # Replace val_labels with your actual labels

# Data augmentation for the training set
train_generator = train_datagen.flow_from_dataframe(train_df, x_col='path', y_col='label',
                                                    target_size=(img_width, img_height),
                                                    batch_size=batch_size, class_mode='categorical',
                                                    subset='training')

# Data augmentation for the validation set
val_generator = val_datagen.flow_from_dataframe(val_df, x_col='path', y_col='label',
                                                target_size=(img_width, img_height),
                                                batch_size=batch_size, class_mode='categorical')

# Data augmentation for the validation set
test_generator = test_datagen.flow_from_dataframe(test_df, x_col='path', y_col='label',
                                                target_size=(img_width, img_height),
                                                batch_size=batch_size, class_mode='categorical')

# Define the CNN model
model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dense(len(train_generator.class_indices), activation='softmax'))

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

# Define the path to save the best model
checkpoint_path = 'saved_model/person1_best_model.h5'

# Create a model checkpoint callback
checkpoint_callback = ModelCheckpoint(checkpoint_path,
                                      monitor='val_loss',
                                      save_best_only=True,
                                      mode='min',
                                      verbose=1)

# Train the model with the callback
history = model.fit(train_generator,
                    steps_per_epoch=len(train_generator),
                    epochs=10,
                    validation_data=val_generator,
                    validation_steps=len(val_generator),
                    callbacks=[checkpoint_callback])

import pandas as pd

df = pd.DataFrame(history.history)

df.insert(0,"epochs",[1,2,3,4,5,6,7,8,9,10], True)
df

# Plot training and validation accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

# Plot training and validation loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(['Train', 'Validation'], loc='upper right')
plt.show()



from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import pandas as pd

# Load the saved best model
saved_model = load_model('person1_best_model.h5')

# Define test data augmentation
test_datagen = ImageDataGenerator(rescale=1.0/255.0)

# Get the true labels for the test set
print(test_labels)

test_df = pd.DataFrame({'path': test_paths, 'label': test_labels})  # Replace val_labels with your actual labels

# Data augmentation for the validation set
test_generator = test_datagen.flow_from_dataframe(test_df, x_col='path', y_col='label',
                                                 target_size=(img_width, img_height),
                                                 batch_size=batch_size, class_mode='categorical')

print(test_generator.classes)

test_predictions = saved_model.predict(test_generator)
# print(test_predictions)

# Evaluate the model
test_loss, test_accuracy = saved_model.evaluate(test_generator)
print("Test Loss:", test_loss)
print("Test Accuracy:", test_accuracy)

answer = np.argmax(test_predictions, axis=1) # , axis=1
print(answer)

y_true = test_generator.classes

from sklearn.metrics import confusion_matrix, classification_report
conf_mat = confusion_matrix(y_true, answer)
# print(conf_mat)
clas_report = classification_report(y_true, answer)
print(clas_report)

print('******************')

import itertools
def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Reds):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        cm = cm.round(2)
        #print("Normalized confusion matrix")
    else:
        cm=cm
        #print('Confusion matrix, without normalization')

    #print(cm)

    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, cm[i, j],
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

np.set_printoptions(precision=2)
classes = test_generator.class_indices

fig1 = plt.figure(figsize=(7,6))
plot_confusion_matrix(conf_mat, classes=classes, title='Confusion matrix, without normalization')
plt.show()

students_list = list(test_generator.class_indices)
print(students_list)

import numpy as np

# Test with given image
student_list = ['Alexander', 'Ava', 'Benjamin', 'Emily', 'Ethan', 'James', 'Mia', 'Olivia', 'Sophia', 'William']
labels_num = student_list.index

print(np.numpy_function)

"""WebCamera based attendance"""



# Webcam

# import dependencies
from IPython.display import display, Javascript, Image
from google.colab.output import eval_js
from base64 import b64decode, b64encode
import cv2
import numpy as np
import PIL
import io
import html
import time

# function to convert the JavaScript object into an OpenCV image
def js_to_image(js_reply):
  """
  Params:
          js_reply: JavaScript object containing image from webcam
  Returns:
          img: OpenCV BGR image
  """
  # decode base64 image
  image_bytes = b64decode(js_reply.split(',')[1])
  # convert bytes to numpy array
  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)
  # decode numpy array into OpenCV BGR image
  img = cv2.imdecode(jpg_as_np, flags=1)

  return img

# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream
def bbox_to_bytes(bbox_array):
  """
  Params:
          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.
  Returns:
        bytes: Base64 image byte string
  """
  # convert array into PIL image
  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')
  iobuf = io.BytesIO()
  # format bbox into png for return
  bbox_PIL.save(iobuf, format='png')
  # format return string
  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))

  return bbox_bytes

# initialize the Haar Cascade face detection model
face_cascade = cv2.CascadeClassifier(cv2.samples.findFile(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'))

def take_photo(filename='photo.jpg', quality=0.8):
  js = Javascript('''
    async function takePhoto(quality) {
      const div = document.createElement('div');
      const capture = document.createElement('button');
      capture.textContent = 'Capture';
      div.appendChild(capture);

      const video = document.createElement('video');
      video.style.display = 'block';
      const stream = await navigator.mediaDevices.getUserMedia({video: true});

      document.body.appendChild(div);
      div.appendChild(video);
      video.srcObject = stream;
      await video.play();

      // Resize the output to fit the video element.
      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);

      // Wait for Capture to be clicked.
      await new Promise((resolve) => capture.onclick = resolve);

      const canvas = document.createElement('canvas');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      canvas.getContext('2d').drawImage(video, 0, 0);
      stream.getVideoTracks()[0].stop();
      div.remove();
      return canvas.toDataURL('image/jpeg', quality);
    }
    ''')
  display(js)

  # get photo data
  data = eval_js('takePhoto({})'.format(quality))
  # get OpenCV format image
  img = js_to_image(data)
  # grayscale img
  gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
  print(gray.shape)
  # get face bounding box coordinates using Haar Cascade
  faces = face_cascade.detectMultiScale(gray)
  # draw face bounding box on image
  for (x,y,w,h) in faces:
      img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
  # save image
  cv2.imwrite(filename, img)

  return filename

# Commented out IPython magic to ensure Python compatibility.
# %cd drive/MyDrive/Colab Notebooks/Attendance_System/Rupendra
# %ls

# prediction from saved file
import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.models import load_model


class ImageClassifier:
    def __init__(self, img_width, img_height):
        self.img_width = img_width
        self.img_height = img_height
        # self.batch_size = 32
        self.model = None
        self.checkpoint_path = 'person1_best_model.h5'

    def load_saved_model(self):
        self.model = load_model(self.checkpoint_path)

    def preprocess_image(self, image_path):
        image = load_img(image_path, target_size=(self.img_width, self.img_height))
        image = img_to_array(image) / 255.0
        image = np.expand_dims(image, axis=0)
        return image

    def predict_image(self, image_path):
        if self.model is None:
            print("Error: Model not loaded.")
            return

        image = self.preprocess_image(image_path)
        predictions = self.model.predict(image)
        class_index = np.argmax(predictions[0])
        return class_index

import datetime
import pandas as pd

def build_excel(year, month, day, time):
  # Check if the file exists
  excel_file = year+'_'+month+'.xlsx'  # file name
  if not os.path.exists(excel_file):
      student = ['Alexander', 'Ava', 'Benjamin', 'Emily', 'Ethan', 'James', 'Mia', 'Rupendra', 'Sophia', 'William']
      rollNo = []
      rollNo = [num+1 for num in range(len(student))]
      print(rollNo)

      df = pd.DataFrame(columns=['Roll No', 'Name'])
      df['Roll No'] = rollNo
      df['Name'] = student
      df.to_excel(excel_file, index=False)
      print(f"Excel file '{excel_file}' created successfully.")
  else:
      df = pd.read_excel(excel_file)
      # Check if the current day column exists
      if day not in df.columns:
        # Add a new column with the current day
        df[day] = day
        df.to_excel(excel_file, index=False)
        print(f"New column '{day}' added to the Excel file.")
      else:
        print(f"Excel file '{excel_file}' already contains column '{day}'.")

      print(f"Excel file '{excel_file}' already exists.")

  return excel_file

# Do attendance

def add_attendance_to_excel(rollno, name):
    # Get the current UTC time
    utc_time = datetime.datetime.utcnow()

    # Calculate the time difference for Nepal (+5:45)
    nepal_time_difference = datetime.timedelta(hours=5, minutes=45)

    # Add the time difference to the current UTC time
    nepal_time = utc_time + nepal_time_difference

    # Get the current date and time
    time = nepal_time.strftime("%H:%M:%S")
    year = nepal_time.strftime("%Y")
    month = nepal_time.strftime("%B")
    day = nepal_time.strftime("%d")

    file_name = build_excel(year, month, day, time)  # Add excel by calling build_excel function
    print(file_name)

    dataframe = pd.read_excel(file_name)
    rollno_mask = (dataframe['Roll No'] == rollno)
    if rollno_mask.any():
        rollno_row = dataframe.loc[rollno_mask]
        if pd.isnull(rollno_row[day].iloc[0]):
            # Add recognized time to the specified column and row
            dataframe.loc[rollno_mask, day] = time

            # Save the modified DataFrame back to the Excel file
            dataframe.to_excel(file_name, index=False)
            print("Attendance for Roll No. {} and Name: {} added.".format(rollno, name))
        else:
            print("Roll No. {} and Name: {} Attendance already registered.".format(rollno, name))
    else:
        print("Roll No. {} not found in the Excel file.".format(rollno))

    return "Attendance for Roll No. {} and Name: {} not added.".format(rollno, name)

try:
    filename = take_photo('photo.jpg')
    print('Saved to {}'.format(filename))

    img_width = img_height = 150

    # Create ImageClassifier instance
    classifier = ImageClassifier(img_width, img_height)

    # Load the saved model
    classifier.load_saved_model()

    # Make a prediction using the saved model
    prediction = classifier.predict_image(filename)

    # Print the predicted class index
    print("Predicted class index:", prediction)
    studentName = ['Alexander', 'Ava', 'Benjamin', 'Emily', 'Ethan', 'James', 'Mia', 'Rupendra', 'Sophia', 'William']
    print(studentName[prediction], "is present")

    # For model
    name = studentName[prediction]  # Predicted student name
    add_attendance_to_excel(prediction+1, name)   # Call add_attendance_to_excel to register attendance of person

    # Show the image which was just taken.
    display(Image(filename))

except Exception as err:
    # Errors will be thrown if the user does not have a webcam or if they do not
    # grant the page permission to access it.
    print(str(err))

